---
title: "NLP"
author: "Ritesh Kumar"
date: "7/2/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

## Clear workspace by deleting all variables
```{r clear workspace}
rm(list=ls())
```

## Install and load libraries
```{r, message=FALSE, warning=FALSE}
library(RSentiment)
library(NLP)
library(openNLP)
#library(maxent)
```

## Parts of speech
```{r}
bio <- readLines("data/nlpText.txt")

bio <- paste(bio, collapse = " ")
print(bio)

# For many kinds of text processing it is sufficient, even preferable to use base R classes. 
# But for NLP we are obligated to use the String class. We need to convert our bio variable to a string.
bio <- as.String(bio)

```


## Sentence and Word Annotations
### Now that we have the file loaded, we can begin to turn it into words and sentences. This is a prerequisite for any other kind of        natural language processing, because those kinds of NLP actions will need to know where the words and sentences are. First we load      the necessary libraries.

```{r}

# Next we need to create annotators for words and sentences. Annotators are created by functions which load the underlying Java           libraries. These functions then mark the places in the string where words and sentences start and end. The annotation functions are     themselves created by functions.

word_ann <- Maxent_Word_Token_Annotator(probs=T)
sent_ann <- Maxent_Sent_Token_Annotator(probs=T)
pos_ann <- Maxent_POS_Tag_Annotator(probs=T)

# These annotators form a “pipeline” for annotating the text in our bio variable. First we have to determine where the sentences are,     then we can determine where the words are. We can apply these annotator functions to our data using the annotate() function.

bio_annotations <- annotate(bio, list(sent_ann, word_ann, pos_ann)) ## Note sequence matters , first sentence then word annotation should come
class(bio_annotations)

bio_annotations
# We can combine the biography and the annotations to create what the NLP package calls an AnnotatedPlainTextDocument. 

bio_doc <- AnnotatedPlainTextDocument(bio, bio_annotations)
# Now we can extract information from our document using accessor functions like sents() to get the sentences and words() to get the words. We could get just the plain text with as.character(bio_doc).
sents(bio_doc) %>% head(2)
words(bio_doc) %>% head(10)

as.character(bio_doc)
```

## Print Pretty 
```{r}
x <- subset(bio_annotations, type == "word")
class(x)

tags <- sapply(x$features, "[[", "POS")
class(tags)
table(tags)
sprintf("%s/%s", bio[x], tags)
```


