---
title: "Unstructure Data Analysis - Assignment-1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

## Problem Statement:
Scrape tweets for the hashtag #datascience and do the following
a. Hour wise or minute wise (depending upon the scrapped tweets) number of tweets -
   draw a line chart
b. Top ten users with more number of tweets
c. Create a new column in the data itself, to identity total number of hashtags in each
   tweet
d. Identity those users who have used #datascience as well as #machinelearning. Plot a bar
   chart top 10 users based on their count

## Deleting all variables
```{r clear workspace}
rm(list=ls())
```
## Install and load libraries
```{r}
library(tm)
library(dplyr)
library(stringi)
library(stringr)
library(wordcloud)
library(ggplot2)
library(plotly)
library(twitteR)
library(ROAuth)
library(httr)
library(base64enc)
library(httk)
```
## Twitter API code

```{r}

api_key <- "MJV2Ue0841ZvZcTjlj2ljPbCM"
api_secret <- "4UJ38gECMGyK6wtmlpd4vxZgb5bWm30SMipJ15D1vFNKToVdwK"
token <- "147624175-zLAkL4BeyLYo7Il4dpwPg2x7C5WvvGBLOnlW6SWM"
token_secret <- "1An3nzmzWGxwhjcTXAqmTJhHuBvr8dO74FNEtK9pJABVX"

# Sys.setenv(http_proxy="http://A038246:!June1234@proxy-mdha.target.com:8080")
# Sys.setenv(https_proxy="http://A038246:!June1234@proxy-mdha.target.com:8080")
# Sys.setenv(HTTP_PROXY="http://A038246:!June1234@proxy-mdha.target.com:8080")
# Sys.setenv(HTTP_PROXY="http://A038246:!June1234@proxy-mdha.target.com:8080")

# setup_twitter_oauth(
#   consumer_key = api_key,
#   consumer_secret = api_secret,
#   access_token = token,
#   access_secret = token_secret)
```
## Scraping tweets with the hashtag #datascience. 
Since, could not find any tweets for 'datascience', therefore scraped the related hashtag like, 'bigdata', 'data' and 'iot'.
Joined the data frames all these tweets and come up with final tweets DF
```{r}
nihDS.tweet <- userTimeline('@NIHDataScience', 3200)
berkelleyData.tweet <- userTimeline('@BerkeleyData', 3200)
kdNuggets.tweet <- userTimeline('@kdnuggets', 3200)

df.nihDS.tweet <- twListToDF(nihDS.tweet)
df.berkelleyData.tweet <- twListToDF(berkelleyData.tweet)
df.kdNuggets.tweet <- twListToDF(kdNuggets.tweet)


df.data.science.tweet <- rbind(df.nihDS.tweet, df.berkelleyData.tweet)
df.data.science.tweet <- rbind(df.data.science.tweet, df.kdNuggets.tweet)

head(df.data.science.tweet)
View(df.data.science.tweet)
dim(df.data.science.tweet)
write.csv(df.data.science.tweet, file = "/Users/ritesh/pad-datascience/R/unstructureData/data/combinedDS1.csv")

```
## Part - 1
Hour wise or minute wise (depending upon the scrapped tweets) number of tweets - draw a line chart
```{r}
df.data.science.tweet$text <- as.character(df.data.science.tweet$text)
df.data.science.tweet$text_transformed <- gsub("[^A-Za-z0-9///'/#/_ ]", " ", df.data.science.tweet$text)
df.data.science.tweet$text_transformed <- lapply(df.data.science.tweet$text_transformed, tolower)

## Parse the date field 'created'
names(df.data.science.tweet)
class(df.data.science.tweet$created)

df.data.science.tweet$cnvdateWithHour <- format(df.data.science.tweet$created, "%d/%m/%y %H") 

tweets_hours <- df.data.science.tweet %>% group_by(cnvdateWithHour) %>% summarise(count=n())
top_100 <- head(tweets_hours, 100)


#View(tweets_hours)

hourlyPlot <-
  ggplot(data=top_100, aes(x=cnvdateWithHour, y=count, group=1)) +
  geom_line() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ggtitle("Tweets Count Vs Day", subtitle="Hour Wise Tweet Count") + 
  xlab("\nDay Wise Hours\n") +
  ylab("\nTweet Count")
ggplotly(hourlyPlot)

```
## Part - 2
Top ten users with more number of tweets
```{r}
length(df.data.science.tweet$id)
length(unique(df.data.science.tweet$id))
```
## Part - 3
Create a new column in the data itself, to identity total number of hashtags in each tweet
```{r}
strcount <- function(x, pattern, split){
  unlist(lapply(
    strsplit(x, split),
       function(z) na.omit(length(grep(pattern, z)))
   ))
}

df.data.science.tweet$hashTagCount <- 
  lapply(df.data.science.tweet$text_transformed, FUN = function(x2) strcount(x2, "#.*", " "))

# unique(df.data.science.tweet$hashTagCount)

```
## Part 4 
Identity those users who have used #datascience as well as #machinelearning. Plot a bar chart top 10 users based on their count
```{r}

# df.data.science.tweet$dsMlHashTagCount <- 
#   lapply(
#     df.data.science.tweet$text_transformed, 
#     FUN = function(x2) strcount(x2, "#datascience*.#machinelearning|#machinelearning*.#datascience", " "))

df.data.science.tweet$mlHashTagCount <- 
  lapply(
    df.data.science.tweet$text_transformed,
    FUN = function(x2) strcount(x2, "#machinelearning", " "))

df.data.science.tweet$dsHashTagCount <- 
  lapply(
    df.data.science.tweet$text_transformed,
    FUN = function(x2) strcount(x2, "#datascience", " "))

#unique(df.data.science.tweet$MlHashTagCount)

df.data.science.tweet$dsHashTagCount <- as.numeric(df.data.science.tweet$dsHashTagCount)
df.data.science.tweet$mlHashTagCount <- as.numeric(df.data.science.tweet$mlHashTagCount)

df.data.science.tweet <- 
  transform(
    df.data.science.tweet, 
    DsMlHashTagCount = ifelse(
      (df.data.science.tweet$dsHashTagCount > 0 & df.data.science.tweet$mlHashTagCount > 0), 
      df.data.science.tweet$dsHashTagCount + df.data.science.tweet$mlHashTagCount, 0))



```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
