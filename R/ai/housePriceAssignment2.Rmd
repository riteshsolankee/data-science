### Deleting all variables
```{r Clear workspace}
rm(list=ls())
```
### Install and load libraries
```{r load}
library(ipred)
library(data.table)
library(caret)
library(Boruta)
library(Hmisc, quietly=TRUE) ## For finding the missing value using 'describe function'
require(plyr) ## for 'llply' function
library(knitr)
library(dplyr)
library(xgboost)
library(ranger)
library(nnet)
library(Metrics)
library(gbm)
```
### Set the working directory
```{r}
setwd("/Users/ritesh/pad-datascience/R/")
```
### Load data and intial analysis
```{r}
train.df <- read.csv("ai/data/train.csv", stringsAsFactors = F)
test.df <- read.csv("ai/data/test.csv", stringsAsFactors = F)
str(train.df)
str(test.df)
names(train.df)
names(test.df)
```
# Description:
# The Ames Housing dataset was retrieved from https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data.
# The dataset represents residential properties in Ames, Iowa from 2006 to 2010. There is a train and a test file.
# The train file has 1460 observations and the test file has 1459 observations. Train dataset contain 81 and test
# dataset contain 80 explanatory variables composed of 46 categorical and 33 continuous variables that describe
# house features such as neighborhood, square footage, number of full bathrooms, and many more. The train file
# contains a response variable column, SalePrice, which is what we will predict in the test set. There is also a
# unique ID for each house sold, but were not used in fitting the models.

##################################################################################
##########  Feature Engineering #################
##################################################################################
## When performing regression, sometimes it makes sense to log-transform the target
## variable when it is skewed
## Importantly, the predictions generated by the final model will also be log-transformed,
## so weâ€™ll need to convert these predictions back to their original form later

## Determine data types in the data set
```{r}
ATTRS <- names(train.df)
data_types <- sapply(ATTRS,function(x){class(train.df[[x]])})
unique_data_types <- unique(data_types)
```

## Separate attributes by data type
```{r}
DATA_ATTR_TYPES <- lapply(unique_data_types,function(x){ names(data_types[data_types == x])})
names(DATA_ATTR_TYPES) <- unique_data_types

Num_NA<-sapply(train.df,function(y)length(which(is.na(y)==T)))
NA_Count<- data.frame(Item=colnames(train.df),Count=Num_NA)
NA_Count
```

## function to calculate 'mode'
```{r}
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
```

## fix charater missing values
```{r}
imputeMissingAttributes <- function(df){
  
  # for character  attributes set missing value
  char_attr <- intersect(names(df),DATA_ATTR_TYPES$character)
  for (x in char_attr){
    print(x)
    print(describe(df[, x])$counts[2])
    print(describe(df[, x])$counts[1])
    misingVal <- describe(df[, x])$counts[2]
    nVal <- describe(df[, x])$counts[1]
    missing_count_percentage <- as.integer(misingVal)/as.integer(nVal)
    print(missing_count_percentage)
    if(missing_count_percentage < 0.015){
      df[[x]][is.na(df[[x]])] <- Mode(df[, x])
      #df[[x]] <- factor(df[[x]])
    }
  }
  # for numeric set missing values to median is the mising value percentage is less than 0.015
  num_attr <- intersect(names(df),DATA_ATTR_TYPES$integer)
  for (x in num_attr){
    print(x)
    print(describe(df[, x])$counts[2])
    print(describe(df[, x])$counts[1])
    misingVal <- describe(df[, x])$counts[2]
    nVal <- describe(df[, x])$counts[1]
    missing_count_percentage <- as.integer(misingVal)/as.integer(nVal)
    print(missing_count_percentage)
    if(missing_count_percentage < 0.015){
      df[[x]][is.na(df[[x]])] <- median(df[, x], na.rm=TRUE)
    }
  }
  ### As per the Project Discription NA values are replaced to No pool.
  df$PoolQC[which(is.na(df$PoolQC))]="NoPool"
  ### As per the Project Discription NA values are replaced to NO Fance
  df$Fence[which(is.na(df$Fence))]="NoFence"
  ### As per the Project Discription NA values are replaced to None
  df$MiscFeature[which(is.na(df$MiscFeature))]="None"
  ### As per the Project Discription NA values are replaced to No Grage
  df$GarageQual[which(is.na(df$GarageQual))]="NoGarage"
  ### As per the Project Discription NA values are replaced to No Grage
  df$GarageCond[which(is.na(df$GarageCond))]="NoGarage"
  ### As per the Project Discription NA values are replaced to No Grage
  df$GarageFinish[which(is.na(df$GarageFinish))]="NoGarage"
  ### As per the Project discription NA values are replaced to "No Fireplace"
  df$FireplaceQu[which(is.na(df$FireplaceQu))]="NoFireplace"
  ### As per the Project Discription NA values are replaced to No Grage
  df$GarageType[which(is.na(df$GarageType))]="NoGarage"
  ### As per the Project Discription NA values are replaced to No Grage
  df$GarageFinish[which(is.na(df$GarageFinish))]="NoGarage"
  df$GarageYrBlt[which(df$GarageYrBlt==2207)]=2007
  ### As per the Project discription NA values are replaced to "NoBasement"
  df$BsmtCond[which(is.na(df$BsmtCond))]="NoBasement"
  df$BsmtExposure[which(is.na(df$BsmtExposure))]="NoBasement"
  df$BsmtQual[which(is.na(df$BsmtQual))]="NoBasement"
  df$BsmtFinType2[which(is.na(df$BsmtFinType2))]="NoBasement"
  df$BsmtFinType1[which(is.na(df$BsmtFinType1))]="NoBasement"
  #### Data Having 93% of NA'S, but replacing the values as "Noalley"
  df$Alley[is.na(df$Alley)]="Noalley"
  
  #### LotFrontage and GarageYrblt is Major missing Values in data
  #### and can be replaced with bagImpute using Propress
  df_preprocess = preProcess(df[,c("LotFrontage","GarageYrBlt")],method="bagImpute")
  summary(df_preprocess) 
  df_pred= predict(df_preprocess,df[,c("LotFrontage","GarageYrBlt")],type="class")
  df$LotFrontage = df_pred$LotFrontage
  df$GarageYrBlt = df_pred$GarageYrBlt
  
  ##return 'df'
  df
}

train_df <- imputeMissingAttributes(train.df)

Num_NA_train <- sapply(train_df,function(y)length(which(is.na(y)==T)))
NA_Count_train <- data.frame(Item=colnames(train_df),Count=Num_NA_train)
NA_Count_train

test_df <- imputeMissingAttributes(test.df)

Num_NA_test <- sapply(test_df,function(y)length(which(is.na(y)==T)))
NA_Count_test <- data.frame(Item=colnames(test_df),Count=Num_NA_test)
NA_Count_test
```

#############################################################################################
########## Features selection (using Boruta) #############
#############################################################################################
## Features selection (using Boruta)
```{r}
extractFeatures <- function(train.dataframe){
  # extract only candidate feature names i.e exclude 'ID' and lable column
  candidate.features <- setdiff(names(train.dataframe),c("Id","SalePrice"))
  data.type <- sapply(candidate.features,function(x){class(train.dataframe[[x]])})
  table(data.type)
  # Determine data types
  explanatory.attributes <- setdiff(names(train.dataframe),c("Id","SalePrice"))
  data.classes <- sapply(explanatory.attributes,function(x){class(train.dataframe[[x]])})
  
  # categorize data types in the data set?
  unique.classes <- unique(data.classes)
  
  attr.data.types <- lapply(unique.classes,function(x){names(data.classes[data.classes==x])})
  names(attr.data.types) <- unique.classes
  
  # Prepare data set for Boruta analysis. As Boruta uses Random forest, missng data needs to be fixed
  # pull out the response variable
  response <- train.dataframe$SalePrice
  
  # remove identifier and response variables
  train.dataframe <- train.dataframe[candidate.features]
  
  ### Run Boruta Analysis ###
  set.seed(13)
  bor.results <- Boruta(train.dataframe,response,
                        maxRuns=101,
                        doTrace=0)
  
  # Print Boruta result
  print(bor.results)
  ## Bucketing attributes as 'Confirmed', 'Tentative' and 'Rejected' :
  CONFIRMED_ATTR <- getSelectedAttributes(bor.results, withTentative = F)
  CONFIRMED_ATTR_WITH_TENTATIVE <- getSelectedAttributes(bor.results, withTentative = T)
  TENTATIVE_ATTR <- CONFIRMED_ATTR_WITH_TENTATIVE[which(!CONFIRMED_ATTR_WITH_TENTATIVE %in% CONFIRMED_ATTR)]
  REJECTED_ATTR <- names(train.dataframe)[!(names(train.dataframe) %in% CONFIRMED_ATTR_WITH_TENTATIVE)]
  PREDICTOR_ATTR <- c(CONFIRMED_ATTR,TENTATIVE_ATTR,REJECTED_ATTR)
  
  return(list(
    CONFIRMED_ATTR = CONFIRMED_ATTR,
    TENTATIVE_ATTR = TENTATIVE_ATTR,
    REJECTED_ATTR = REJECTED_ATTR, 
    PREDICTOR_ATTR = PREDICTOR_ATTR,
    BOR_RESULT = bor.results))
}

attr_list <- extractFeatures(train_df)
# create folds for training
set.seed(13)
data_folds <- createFolds(train_df$SalePrice, k=5)

### plot the boruta variable importance chart.
# Blue boxplots correspond to minimal, average and maximum Z score of a shadow attribute. Red, yellow and green boxplots
# represent Z scores of rejected, tentative and confirmed attributes respectively.
plot(attr_list$BOR_RESULT, xlab = "", xaxt = "n")
lz<-lapply(1:ncol(attr_list$BOR_RESULT$ImpHistory),function(i)attr_list$BOR_RESULT$ImpHistory[is.finite(attr_list$BOR_RESULT$ImpHistory[,i]),i])
names(lz) <- colnames(attr_list$BOR_RESULT$ImpHistory)
Labels <- sort(sapply(lz,median))
axis(side = 1,las=2,labels = names(Labels), at = 1:ncol(attr_list$BOR_RESULT$ImpHistory), cex.axis = 0.7)

attStats(attr_list$BOR_RESULT)

#########   ------  ###############
#final.boruta <- TentativeRoughFix(bor.results)
#plot(final.boruta, xlab = "", xaxt = "n")
#lz<-lapply(1:ncol(final.boruta$ImpHistory),function(i)final.boruta$ImpHistory[is.finite(final.boruta$ImpHistory[,i]),i])
#names(lz) <- colnames(final.boruta$ImpHistory)
#Labels <- sort(sapply(lz,median))
#axis(side = 1,las=2,labels = names(Labels), at = 1:ncol(final.boruta$ImpHistory), cex.axis = 0.7)
#########   ------  ###############
```
## boxplot to dipict influincing attributes
```{r}
library(scales)
ggplot(train, aes(x=SalePrice)) + geom_histogram(col = 'white') + theme_light() +scale_x_continuous(labels = comma)
summary(train[,c("SalePrice")])
#Normalize distribution
ggplot(train, aes(x=log(SalePrice+1))) + geom_histogram(col = 'white') + theme_light()
```

###################################################################################################
###########   Model Stacking      #################
###################################################################################################

## Feature Set 1 - Boruta Confirmed and tentative Attributes
```{r}
prepL0FeatureSet1 <- function(df) {
  id <- df$Id
  if (class(df$SalePrice) != "NULL") {
    y <- log(df$SalePrice)
  } else {
    y <- NULL
  }
  predictor_vars <- c(attr_list$CONFIRMED_ATTR,attr_list$TENTATIVE_ATTR)
  predictors <- df[predictor_vars]
  # for character  atributes set missing value
  char_attr <- intersect(predictor_vars,DATA_ATTR_TYPES$character)
  for (x in char_attr){
    predictors[[x]] <- factor(predictors[[x]])
  }
  return(list(id=id,y=y,predictors=predictors))
}

L0FeatureSet1 <- list(
  train=prepL0FeatureSet1(train_df),
  test=prepL0FeatureSet1(test_df))
```

## Feature Set 2 (xgboost) - Boruta Confirmed Attributes
```{r}
prepL0FeatureSet2 <- function(df) {
  id <- df$Id
  if (class(df$SalePrice) != "NULL") {
    y <- log(df$SalePrice)
  } else {
    y <- NULL
  }
  predictor_vars <- c(attr_list$CONFIRMED_ATTR,attr_list$TENTATIVE_ATTR)
  predictors <- df[predictor_vars]
  
  # for character  atributes set missing value
  char_attr <- intersect(predictor_vars,DATA_ATTR_TYPES$character)
  for (x in char_attr){
    predictors[[x]] <- as.numeric(factor(predictors[[x]]))
  }
  
  return(list(id=id,y=y,predictors=as.matrix(predictors)))
}
L0FeatureSet2 <- list(
  train=prepL0FeatureSet2(train_df),                    
  test=prepL0FeatureSet2(test_df))
```

## Helper Function For Training. train model on one data fold
```{r}
trainOneFold <- function(this_fold,feature_set) {
  # get fold specific Cross Validation data
  cv.data <- list()
  cv.data$predictors <- feature_set$train$predictors[this_fold,]
  cv.data$ID <- feature_set$train$id[this_fold]
  cv.data$y <- feature_set$train$y[this_fold]
  
  # get training data for specific fold
  train.data <- list()
  train.data$predictors <- feature_set$train$predictors[-this_fold,]
  train.data$y <- feature_set$train$y[-this_fold]
  
  set.seed(825)
  fitted_mdl <- do.call(train,
                        c(
                          list(x=train.data$predictors,y=train.data$y),
                          CARET.TRAIN.PARMS,
                          MODEL.SPECIFIC.PARMS,
                          CARET.TRAIN.OTHER.PARMS))
  
  yhat <- predict(fitted_mdl,newdata = cv.data$predictors,type = "raw")
  score <- rmse(cv.data$y,yhat)
  ans <- list(fitted_mdl=fitted_mdl,
              score=score,
              predictions=data.frame(ID=cv.data$ID,yhat=yhat,y=cv.data$y))
  return(ans)
}

```

######### GBM Model #####################
## GBM model
```{r}
# set caret training parameters
CARET.TRAIN.PARMS <- list(method="gbm")   

CARET.TUNE.GRID <-  expand.grid(n.trees=100, 
                                interaction.depth=10, 
                                shrinkage=0.1,
                                n.minobsinnode=10)
MODEL.SPECIFIC.PARMS <- list(verbose=0) #NULL # Other model specific parameters
# model specific training parameter
CARET.TRAIN.CTRL <- trainControl(method="none",
                                 verboseIter=FALSE,
                                 classProbs=FALSE)
CARET.TRAIN.OTHER.PARMS <- list(trControl=CARET.TRAIN.CTRL,
                                tuneGrid=CARET.TUNE.GRID,
                                metric="RMSE")

# generate features for Level 1
gbm_set <- llply(data_folds,trainOneFold,L0FeatureSet1)
gbm_set
# final model fit
gbm_mdl <- do.call(train,
                   c(list(x=L0FeatureSet1$train$predictors,y=L0FeatureSet1$train$y),
                     CARET.TRAIN.PARMS,
                     MODEL.SPECIFIC.PARMS,
                     CARET.TRAIN.OTHER.PARMS))

# Cross validation Error Estimate
cv_y <- do.call(c,lapply(gbm_set,function(x){x$predictions$y}))
cv_yhat <- do.call(c,lapply(gbm_set,function(x){x$predictions$yhat}))
rmse(cv_y,cv_yhat)

cat("Average CV rmse:",mean(do.call(c,lapply(gbm_set,function(x){x$score}))))

# create test submission.
# A prediction is made by averaging the predictions made by using the models
# fitted for each fold.
test_gbm_yhat <- predict(gbm_mdl,newdata = L0FeatureSet1$test$predictors,type = "raw")
gbm_submission <- cbind(Id=L0FeatureSet1$test$id,SalePrice=exp(test_gbm_yhat))
write.csv(gbm_submission,file="/Users/ritesh/Documents/DataScience/AdvancedML/gbm_sumbission.csv",row.names=FALSE)
```

####################  xgboost ################
## xgboost model
```{r}
# set caret training parameters
CARET.TRAIN.PARMS <- list(method="xgbTree")   
CARET.TUNE.GRID <-  expand.grid(nrounds=800, 
                                max_depth=10, 
                                eta=0.03, 
                                gamma=0.1, 
                                colsample_bytree=0.4, 
                                min_child_weight=1,
                                subsample = 1)
MODEL.SPECIFIC.PARMS <- list(verbose=0) #NULL # Other model specific parameters
# model specific training parameter
CARET.TRAIN.CTRL <- trainControl(method="none",
                                 verboseIter=FALSE,
                                 classProbs=FALSE)
CARET.TRAIN.OTHER.PARMS <- list(trControl=CARET.TRAIN.CTRL,
                                tuneGrid=CARET.TUNE.GRID,
                                metric="RMSE")
# generate Level 1 features
xgb_set <- llply(data_folds,trainOneFold,L0FeatureSet2)
# final model fit
xgb_mdl <- do.call(train,
                   c(list(x=L0FeatureSet2$train$predictors,y=L0FeatureSet2$train$y),
                     CARET.TRAIN.PARMS,
                     MODEL.SPECIFIC.PARMS,
                     CARET.TRAIN.OTHER.PARMS))
# CV Error Estimate
cv_y <- do.call(c,lapply(xgb_set,function(x){x$predictions$y}))
cv_yhat <- do.call(c,lapply(xgb_set,function(x){x$predictions$yhat}))
rmse(cv_y,cv_yhat)
cat("Average CV rmse:",mean(do.call(c,lapply(xgb_set,function(x){x$score}))))
# create test submission.
# A prediction is made by averaging the predictions made by using the models
# fitted for each fold.
test_xgb_yhat <- predict(xgb_mdl,newdata = L0FeatureSet2$test$predictors,type = "raw")
xgb_submission <- cbind(Id=L0FeatureSet2$test$id,SalePrice=exp(test_xgb_yhat))

write.csv(xgb_submission,file="/Users/ritesh/Documents/DataScience/AdvancedML/xgb_sumbission.csv",row.names=FALSE)
```

########################### ranger Model   ############################
## ranger model
```{r}
# set caret training parameters
CARET.TRAIN.PARMS <- list(method="ranger")   
CARET.TUNE.GRID <-  expand.grid(mtry=2*as.integer(sqrt(ncol(L0FeatureSet1$train$predictors))))
MODEL.SPECIFIC.PARMS <- list(verbose=0,num.trees=500) #NULL # Other model specific parameters
# model specific training parameter
CARET.TRAIN.CTRL <- trainControl(method="none",
                                 verboseIter=FALSE,
                                 classProbs=FALSE)
CARET.TRAIN.OTHER.PARMS <- list(trControl=CARET.TRAIN.CTRL,
                                tuneGrid=CARET.TUNE.GRID,
                                metric="RMSE")
# generate Level 1 features
rngr_set <- llply(data_folds,trainOneFold,L0FeatureSet1)
# final model fit
rngr_mdl <- do.call(train,
                    c(list(x=L0FeatureSet1$train$predictors,y=L0FeatureSet1$train$y),
                      CARET.TRAIN.PARMS,
                      MODEL.SPECIFIC.PARMS,
                      CARET.TRAIN.OTHER.PARMS))
# CV Error Estimate
cv_y <- do.call(c,lapply(rngr_set,function(x){x$predictions$y}))
cv_yhat <- do.call(c,lapply(rngr_set,function(x){x$predictions$yhat}))
rmse(cv_y,cv_yhat)
cat("Average CV rmse:",mean(do.call(c,lapply(rngr_set,function(x){x$score}))))

# create test submission.
# A prediction is made by averaging the predictions made by using the models
# fitted for each fold.
test_rngr_yhat <- predict(rngr_mdl,newdata = L0FeatureSet1$test$predictors,type = "raw")
rngr_submission <- cbind(Id=L0FeatureSet1$test$id,SalePrice=exp(test_rngr_yhat))

write.csv(rngr_submission,file="/Users/ritesh/Documents/DataScience/AdvancedML/rngr_sumbission.csv",row.names=FALSE)
```

########################### Level 1 Model Training ########################
## Level -1 neural net Model
```{r}
gbm_yhat <- do.call(c,lapply(gbm_set,function(x){x$predictions$yhat}))
xgb_yhat <- do.call(c,lapply(xgb_set,function(x){x$predictions$yhat}))
rngr_yhat <- do.call(c,lapply(rngr_set,function(x){x$predictions$yhat}))

# create Feature Set
L1FeatureSet <- list()

L1FeatureSet$train$id <- do.call(c,lapply(gbm_set,function(x){x$predictions$ID}))
L1FeatureSet$train$y <- do.call(c,lapply(gbm_set,function(x){x$predictions$y}))
predictors <- data.frame(gbm_yhat,xgb_yhat,rngr_yhat)
predictors_rank <- t(apply(predictors,1,rank))
colnames(predictors_rank) <- paste0("rank_",names(predictors))
L1FeatureSet$train$predictors <- predictors #cbind(predictors,predictors_rank)

L1FeatureSet$test$id <- gbm_submission[,"Id"]
L1FeatureSet$test$predictors <- data.frame(gbm_yhat=test_gbm_yhat,
                                           xgb_yhat=test_xgb_yhat,
                                           rngr_yhat=test_rngr_yhat)
############################ Neural Net Model ################################
# set caret training parameters
CARET.TRAIN.PARMS <- list(method="nnet") 
CARET.TUNE.GRID <-  NULL  # NULL provides model specific default tuning parameters
# model specific training parameter
CARET.TRAIN.CTRL <- trainControl(method="repeatedcv",
                                 number=5,
                                 repeats=1,
                                 verboseIter=FALSE)
CARET.TRAIN.OTHER.PARMS <- list(trControl=CARET.TRAIN.CTRL,
                                maximize=FALSE,
                                tuneGrid=CARET.TUNE.GRID,
                                tuneLength=7,
                                metric="RMSE")
MODEL.SPECIFIC.PARMS <- list(verbose=FALSE,linout=TRUE,trace=FALSE) #NULL # Other model specific parameters
# train the model
set.seed(825)
l1_nnet_mdl <- do.call(train,c(list(x=L1FeatureSet$train$predictors,y=L1FeatureSet$train$y),
                               CARET.TRAIN.PARMS,
                               MODEL.SPECIFIC.PARMS,
                               CARET.TRAIN.OTHER.PARMS))
l1_nnet_mdl
cat("Average CV rmse:",mean(l1_nnet_mdl$resample$RMSE),"\n")

test_l1_nnet_yhat <- predict(l1_nnet_mdl,newdata = L1FeatureSet$test$predictors,type = "raw")
l1_nnet_submission <- cbind(Id=L1FeatureSet$test$id,SalePrice=exp(test_l1_nnet_yhat))
colnames(l1_nnet_submission) <- c("Id","SalePrice")

write.csv(l1_nnet_submission,file="/Users/ritesh/Documents/DataScience/AdvancedML/l1_nnet_submission.csv",row.names=FALSE)

```

